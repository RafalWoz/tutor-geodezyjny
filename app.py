import os
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.document_loaders import PyPDFLoader

# --- ≈Åadowanie dokument√≥w ---
def load_documents(folder="documents"):
    docs = []
    for file in os.listdir(folder):
        if file.endswith(".pdf"):
            loader = PyPDFLoader(os.path.join(folder, file))
            docs.extend(loader.load())
    return docs

# --- Tworzenie bazy embedding√≥w ---
@st.cache_resource
def create_vectorstore():
    docs = load_documents()
    embeddings = OpenAIEmbeddings(openai_api_key=os.environ["OPENAI_API_KEY"])
    return FAISS.from_documents(docs, embeddings)

st.title("üó∫Ô∏è Tutor do Uprawnie≈Ñ Geodezyjnych")
vectorstore = create_vectorstore()
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
llm = ChatOpenAI(openai_api_key=os.environ["OPENAI_API_KEY"], model_name="gpt-4o")
qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever=retriever)

# --- UI ---
chat_history = []
query = st.text_input("‚ùì Zadaj pytanie lub popro≈õ o quiz:")
if query:
    result = qa_chain({"question": query, "chat_history": chat_history})
    st.write(result["answer"])
    chat_history.append((query, result["answer"]))

if st.button("üéØ Wygeneruj quiz z bie≈ºƒÖcego prawa"):
    result = qa_chain({"question": "Stw√≥rz 5 pyta≈Ñ testowych wielokrotnego wyboru na podstawie przepis√≥w.", "chat_history": chat_history})
    st.write(result["answer"])
